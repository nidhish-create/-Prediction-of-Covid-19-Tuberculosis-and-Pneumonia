{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"        
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wpIYp8aMANph"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import Image as disp_image\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 256\n",
        "img_width = 256\n",
        "channels = 3\n",
        "batch_size = 8\n",
        "epochs = 20\n",
        "train_datagen = ImageDataGenerator(rotation_range=40,\n",
        " width_shift_range=0.2,\n",
        " height_shift_range=0.2,\n",
        " rescale=1./255,\n",
        " shear_range=0.2,\n",
        " zoom_range=0.2,\n",
        " #horizontal_flip=True,\n",
        "fill_mode='nearest',\n",
        " validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "training_set = train_datagen.flow_from_directory(\n",
        " './dataset/training',\n",
        " target_size = (img_height, img_width),\n",
        " batch_size = batch_size,\n",
        " class_mode = 'binary',\n",
        " subset = 'training',\n",
        " shuffle=True)\n",
        "validation_set = train_datagen.flow_from_directory(\n",
        " './dataset/training',\n",
        " target_size = (img_height, img_width),\n",
        " batch_size = batch_size,\n",
        " class_mode = 'binary',\n",
        " subset = 'validation',\n",
        " shuffle=False)\n",
        "test_set = train_datagen.flow_from_directory(\n",
        " './dataset/test',\n",
        " target_size = (img_height, img_width),\n",
        " batch_size = 1,\n",
        " shuffle = False,\n",
        " class_mode = 'binary')\n",
        "print(training_set.class_indices)\n"
      ],
      "metadata": {
        "id": "u8dXxmfwAdaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Covid image example\n",
        "img_files = os.listdir('dataset/training/covid')\n",
        "img_path = img_files[np.random.randint(0,len(img_files))]\n",
        "img = Image.open('dataset/training/covid/{}'.format(img_path))\n",
        "img.thumbnail((500, 500))\n",
        "display(img)"
      ],
      "metadata": {
        "id": "EqcpPgcUAhLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Healthy image example\n",
        "img_files = os.listdir('dataset/training/healthy')\n",
        "img_path = img_files[np.random.randint(0,len(img_files))]\n",
        "img = Image.open('dataset/training/healthy/{}'.format(img_path))\n",
        "img.thumbnail((500, 500))\n",
        "display(img)\n"
      ],
      "metadata": {
        "id": "NRMszlDCAwSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16\n",
        "model = VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, channels))\n",
        "for layer in model.layers[:-5]:\n",
        " layer.trainable = False\n",
        "top_model = Sequential()\n",
        "top_model.add(model)\n",
        "top_model.add(Flatten())\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "print(model.summary())\n",
        "print(top_model.summary())"
      ],
      "metadata": {
        "id": "h24vvNYDAyH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Model\n",
        "top_model.compile(loss='binary_crossentropy',\n",
        " optimizer=optimizers.RMSprop(lr=1e-4, decay=1e-6),\n",
        " metrics=['accuracy'])\n",
        "# Save Model\n",
        "history = top_model.fit_generator(\n",
        " training_set,\n",
        " steps_per_epoch=training_set.n // batch_size,\n",
        " epochs=epochs,\n",
        " validation_data=validation_set,\n",
        " validation_steps=validation_set.n // batch_size)\n",
        "# Save Model\n",
        "top_model.save('output/covid_model.h5', save_format='h5')"
      ],
      "metadata": {
        "id": "XfgjqzrMA0j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Accuracy and Loss\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SDAAR57CA3NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Performance on test set\n",
        "test_pred = top_model.evaluate_generator(test_set,\n",
        " steps=test_set.n//batch_size,\n",
        " use_multiprocessing=False,\n",
        " verbose=1)\n",
        "print('Test loss: ', test_pred[0])\n",
        "print('Test accuracy: ', test_pred[1])\n"
      ],
      "metadata": {
        "id": "m3JkxgcvA6h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = top_model.predict(test_set,\n",
        " steps=test_set.n,\n",
        " use_multiprocessing=False,\n",
        " verbose=1)\n",
        "test_pred_class = (test_pred >= 0.5)*1\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(test_set.classes,\n",
        " test_pred_class)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix');\n",
        "ax.xaxis.set_ticklabels(['COVID-19', 'Healthy']); ax.yaxis.set_ticklabels(['COVID-19', 'Healthy']);"
      ],
      "metadata": {
        "id": "WHpc9Y_8A9zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "print(classification_report(test_set.classes,\n",
        " test_pred_class))"
      ],
      "metadata": {
        "id": "E7o2wD45BAIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 256\n",
        "img_width = 256\n",
        "channels = 3\n",
        "batch_size = 8\n",
        "epochs = 20\n",
        "train_datagen = ImageDataGenerator(rotation_range=40,\n",
        " width_shift_range=0.2,\n",
        " height_shift_range=0.2,\n",
        " rescale=1./255,\n",
        " shear_range=0.2,\n",
        " zoom_range=0.2,\n",
        " #horizontal_flip=True,\n",
        "fill_mode='nearest',\n",
        " validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "training_set = train_datagen.flow_from_directory('./multiclass_dataset/training',\n",
        " target_size = (img_height, img_width),\n",
        " batch_size = batch_size,\n",
        " class_mode = 'categorical',\n",
        " subset = 'training',\n",
        " shuffle=True)\n",
        "validation_set = train_datagen.flow_from_directory('./multiclass_dataset/training',\n",
        " target_size = (img_height, img_width),\n",
        " batch_size = batch_size,\n",
        " class_mode = 'categorical',\n",
        " subset = 'validation',\n",
        " shuffle=False)\n",
        "test_set = train_datagen.flow_from_directory('./multiclass_dataset/test',\n",
        " target_size = (img_height, img_width),\n",
        " batch_size = 1,\n",
        " shuffle = False,\n",
        " class_mode = 'categorical')\n",
        "print(training_set.class_indices)"
      ],
      "metadata": {
        "id": "9QbsC1yUBC9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16\n",
        "model = VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, channels))\n",
        "for layer in model.layers[:-5]:\n",
        " layer.trainable = False\n",
        "top_model = Sequential()\n",
        "top_model.add(model)\n",
        "top_model.add(Flatten())\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(len(training_set.class_indices), activation='softmax'))\n",
        "print(model.summary())\n",
        "print(top_model.summary())"
      ],
      "metadata": {
        "id": "9ayOa3yrBGcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Model\n",
        "top_model.compile(loss='categorical_crossentropy',\n",
        " optimizer=optimizers.RMSprop(lr=1e-4, decay=1e-6),\n",
        " metrics=['accuracy'])\n",
        "save_best = ModelCheckpoint('output/covid_pneumonia_model.h5', monitor='val_loss', verbose=0, save_best_only=True)\n",
        "# Train Model\n",
        "history = top_model.fit_generator(\n",
        " training_set,\n",
        " steps_per_epoch=training_set.n // batch_size,\n",
        " epochs=epochs,\n",
        " validation_data=validation_set,\n",
        " validation_steps=validation_set.n // batch_size,\n",
        " callbacks=[save_best])\n",
        "# Save Model\n",
        "top_model.save('output/covid_pneumonia_model.h5', save_format='h5')"
      ],
      "metadata": {
        "id": "dKWCXCDUCNo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Accuracy and Loss\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ux39o0h0CQSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = top_model.predict(test_set,\n",
        " steps=test_set.n,\n",
        " use_multiprocessing=False,\n",
        " verbose=1)\n",
        "test_pred_class = np.argsort(test_pred)[:,2]\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(test_set.classes,\n",
        " test_pred_class)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix');\n",
        "ax.xaxis.set_ticklabels(['COVID-19', 'Healthy', 'Pneumonia']); ax.yaxis.set_ticklabels(['COVID-19', 'Healthy', 'Pneumonia']);"
      ],
      "metadata": {
        "id": "ymWYgDdpCSus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "print(classification_report(test_set.classes,\n",
        " test_pred_class))"
      ],
      "metadata": {
        "id": "dJTyGbO_CU4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy_score(test_set.classes,\n",
        " test_pred_class)"
      ],
      "metadata": {
        "id": "SozEYy3dCXM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5tlXoKfsCZk7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
